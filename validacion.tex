\chapter{Validación}

Para evaluar la solución se hicieron pruebas con usuarios y se les pidió que contestaran un cuestionario. 

Los participantes fueron estudiantes de la Facultad de Ciencias Físicas y Matemáticas que accedieron a ser parte de la investigación. Estos fueron reclutados usando el foro institucional y el grupo de Telegram de los estudiantes del Departamento de Ciencias de la Computación.

Para realizar estas pruebas se le pidió la autorización al comité de ética y todos los usuarios firmaron un consentimiento informado antes de participar. En el anexo~\ref{anexo:consentimiento} se puede ver el consentimiento informado.

Las pruebas con usuarios consistieron en que a cada participante se le explicó el proceso, luego se le dio una breve explicación sobre cómo usar la herramienta y se le pidió que utilice la herramienta para generar una visualización de cierta operación. Posteriormente se le pidió que conteste un cuestionario.

El cuestionario tiene tres partes. La primera parte consiste en el System Usability Scale (SUS) ---un método estándar para evaluar la usabilidad de sistemas informáticos---, la segunda parte corresponde a preguntas abiertas sobre la herramienta y la tercera parte corresponde a una caracterización del participante. En el anexo~\ref{anexo:cuestionario} se puede ver el cuestionario que fue utilizado.

La escala SUS fue introducida en~\cite{brooke1996quick} como un método sencillo para evaluar la usabilidad de sistemas informáticos y se ha vuelto un método estándar en la industria para medir la usabilidad de todo tipo de sistemas. En~\cite{evaluation-of-sus} analizan 10 años de datos de SUS y encuentran que esta escala es una herramienta altamente robusta y versátil para las evaluaciones de usabilidad. Como la versión original está en inglés se utilizó la versión en español adaptada y validada en~\cite{spanish-sus} con una modificación. La modificación consistió en que se cambió ``\textit{Me sentí muy confiado al usar la herramienta}'' por ``\textit{Me sentí muy confiado o confiada al usar la herramienta}'' con el objetivo de hacer el cuestionario más inclusivo.

Las preguntas abiertas que se le hicieron los participantes fueron: ``\textit{¿Qué te gustó de la herramienta? ¿Por qué?}'', ``\textit{¿Qué no te gustó de la herramienta? ¿Por qué?}'', y ``\textit{¿Cómo podría ser mejor la herramienta?}'' Se escogieron estas preguntas para tener una idea de porque a los usuarios les gustó o no la herramienta y también de cómo esta se podría mejorar en el futuro.

En la caracterización se preguntó por edad, género y avance curricular. La edad se preguntó en intervalos de 2 años entre los 18 años y 30 o más años. Se preguntó de esta manera para evitar poder identificar a los participantes a partir de sus respuestas. Para el género las opciones eran \textit{Hombre}, \textit{Mujer}, \textit{Otro} y \textit{Prefiero no responder}. Para el avance curricular se les pidió a los estudiantes que marcaran todos los cursos que han cursado o estaban cursando de una lista de 5 cursos obligatorios de Ingeniería Civil en Computación. Cómo los cursos seleccionados requieren tomar el curso anterior en la lista, esta respuesta se puede representar con un número del 0 al 5, donde el número representa que el estudiante ha tomado todos los cursos de la lista hasta ese número.

Se preguntó por edad y género porque en~\cite{evaluation-of-sus} se observa cierta relación entre estos factores y el puntaje obtenido en SUS. Se preguntó por avance curricular porque se cree que puede haber una relación entre el nivel de conocimiento en programación o en ciencias de la computación y la facilidad para usar la herramienta.

En total participaron 12 estudiantes. De estos, 10 se identificaron como hombres, 1 como mujer y 1 como otro. La edad promedio de los participantes fue 21.5 años. En cuanto al avance curricular, 9 de los estudiantes marcaron 2, lo que significa que han cursado los cursos de la lista hasta Algoritmos y Estructuras de Datos. Utilizando el sistema de puntuación de SUS se obtuvo un puntaje promedio de 82.5, con una desviación estándar de 5.8. Este puntaje se encuentra entre los percentiles 90 y 95 usando la escala de~\cite{quantifying-the-user-experience}.

En cuanto a las preguntas abiertas. En la primera pregunta, \textit{¿Qué te gustó de la herramienta? ¿Por qué?}, las respuestas más frecuentes mencionaban que la herramienta muestra el código fuente que dio origen a la operación y que solo requiere agregar dos líneas de código para usarla. En la segunda pregunta, \textit{¿Qué no te gustó de la herramienta? ¿Por qué?}, no hubo respuestas significativamente más comunes que otras. Sin embargo, una respuesta que se repitió dos veces tiene que ver con que al eliminar un nodo de la lista este visualmente se mueve hacia abajo de la lista original en vez de desaparecer. En la tercera pregunta, \textit{¿Cómo podría ser mejor la herramienta?}, la respuesta más frecuenta estaba relacionada permitir visualizar otras estructuras de datos que no sean listas enlazadas.

Estos resultados muestran que la herramienta soluciona el problema abordado y cumple con el requisito de permitirle al usuario utilizar la herramienta agregando la menor cantidad de instrumentación necesaria a su código. Sin embargo, también presenta oportunidades de mejora. La principal oportunidad de mejora tiene que ver con permitir generar visualizaciones de otras estructuras de datos. Otra oportunidad de mejora sería mostrar en la visualización las referencias a los nodos del \textit{contenedor}. Esto ayudaría a los usuarios a entender que está pasando en algunos de los casos que ocurrieron durante las pruebas con usuarios.
